{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality, personalized content such as articles, social media posts, product descriptions, and even entire books.\n",
      "2. **Virtual Assistants**: Companies like Amazon and Microsoft use generative AI to power their virtual assistants, enabling them to understand natural language and respond accordingly.\n",
      "3. **Chatbots**: Generative AI is used to create more sophisticated chatbots that can engage in conversations, provide customer support, and even sell products.\n",
      "4. **Personalized Recommendations**: Retailers like Netflix and Amazon use generative AI to suggest personalized product recommendations based on user behavior and preferences.\n",
      "5. **Data Analysis and Visualization**: Generative AI can analyze large datasets, identify patterns, and create visualizations that help businesses make data-driven decisions.\n",
      "6. **Image and Video Generation**: Generative AI can generate high-quality images and videos for various applications, such as marketing, advertising, and entertainment.\n",
      "7. **Music Composition**: Companies like Jukedeck and AIVA use generative AI to compose music for films, TV shows, and video games.\n",
      "8. **Language Translation**: Generative AI is being used to improve language translation software, enabling more accurate and natural-sounding translations.\n",
      "9. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and increasing efficiency.\n",
      "10. **Product Design**: Generative AI can design new products, such as furniture, clothing, or electronics, based on customer preferences and design parameters.\n",
      "\n",
      "Some specific business applications of generative AI include:\n",
      "\n",
      "* **Marketing automation**: Using generative AI to create personalized marketing campaigns and automate email marketing.\n",
      "* **Customer service**: Using generative AI-powered chatbots to provide 24/7 customer support.\n",
      "* **Product development**: Using generative AI to generate new product ideas and designs based on customer feedback and market trends.\n",
      "* **Financial analysis**: Using generative AI to analyze financial data, identify trends, and make predictions about future performance.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as articles, blog posts, social media posts, and product descriptions, reducing the need for human writers.\n",
      "2. **Image and Video Creation**: Generative AI can create realistic images and videos, which can be used in advertising, marketing, and entertainment industries, or as a replacement for traditional photographers and videographers.\n",
      "3. **Product Design**: Generative AI can assist designers in creating new product designs, reducing the time and cost associated with traditional design processes.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI can be used to power chatbots and virtual assistants that provide customer support, answering frequently asked questions and routing complex issues to human representatives.\n",
      "5. **Predictive Analytics**: Generative AI can analyze large datasets and identify patterns, enabling businesses to make more accurate predictions about future trends, customer behavior, and market conditions.\n",
      "6. **Marketing Automation**: Generative AI can be used to automate marketing campaigns, personalize messaging, and create targeted ads based on customer data and behavior.\n",
      "7. **Financial Analysis**: Generative AI can analyze large datasets of financial transactions, identifying trends, patterns, and potential risks, enabling businesses to make more informed investment decisions.\n",
      "8. **Customer Service**: Generative AI-powered chatbots and virtual assistants can help businesses provide 24/7 customer support, reducing the need for human customer service representatives.\n",
      "9. **Language Translation**: Generative AI can be used to translate languages in real-time, enabling businesses to expand their reach into new markets without language barriers.\n",
      "10. **Creative Writing**: Generative AI can assist writers with generating ideas, completing drafts, and even writing entire articles or books, reducing the time and effort required for human writers.\n",
      "\n",
      "Some examples of companies using Generative AI include:\n",
      "\n",
      "* **Grammarly**: Uses generative AI to analyze grammar, spelling, and punctuation errors in written content.\n",
      "* **Adobe**: Uses generative AI to create realistic images and videos for advertising and marketing campaigns.\n",
      "* **Google**: Uses generative AI to improve its language translation capabilities.\n",
      "* **Amazon**: Uses generative AI to power its chatbots and virtual assistants.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: AI-powered tools can generate high-quality content such as articles, social media posts, videos, and images, saving time and resources for businesses.\n",
      "2. **Product Design and Development**: Generative AI can design new product concepts, prototypes, and patterns, reducing the need for manual design and enabling faster innovation cycles.\n",
      "3. **Marketing and Advertising**: AI-generated content, such as ad copy and visual assets, can be used to personalize marketing campaigns and improve customer engagement.\n",
      "4. **Customer Service**: Chatbots powered by Generative AI can provide 24/7 support to customers, freeing up human operators to focus on more complex issues.\n",
      "5. **Data Analysis and Visualization**: Generative AI algorithms can analyze large datasets and generate visualizations that help businesses gain insights into customer behavior, market trends, and other key metrics.\n",
      "6. **Supply Chain Optimization**: AI-powered predictive analytics can identify potential bottlenecks in supply chains, enabling proactive measures to optimize logistics and reduce costs.\n",
      "7. **Financial Modeling and Forecasting**: Generative AI models can predict stock prices, detect patterns in financial data, and forecast revenue growth.\n",
      "8. **Human Resource Management**: AI-generated insights from HR data can help businesses identify talent gaps, optimize recruitment strategies, and improve employee engagement.\n",
      "9. **Cybersecurity**: Generative AI-powered security tools can analyze network traffic for potential threats, automatically responding to anomalies and helping prevent cyber attacks.\n",
      "10. **Healthcare**: AI-generated medical images can aid in diagnosis, while predictive analytics can help forecast patient outcomes and identify high-risk patients.\n",
      "\n",
      "Businesses can also use Generative AI to:\n",
      "\n",
      "* Automate repetitive tasks and processes\n",
      "* Enhance customer experience through personalized engagement\n",
      "* Improve product development cycles with AI-powered design tools\n",
      "* Optimize resources by predicting demand for certain products or services\n",
      "* Gain insights from large datasets and complex patterns\n",
      "\n",
      "These applications demonstrate the vast potential of Generative AI in transforming businesses and improving their operations, marketing strategies, and bottom lines.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502127b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEEPSEEK_MODEL = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand the basic concepts behind neural networks, attention mechanisms, and transformers. I know that LLMs are language models, but I'm not entirely sure how each of these components works together. Let me try to break it down step by step.\n",
      "\n",
      "First, neural networks. I remember hearing that they have something to do with artificial neural networks in the brain or computer systems. From what I can gather, a neural network processes data through layers of nodes or neurons. Each layer might process information differently. The key idea here is how these layers work together—maybe each layer takes input from the previous layer and combines it somehow to make predictions or decisions.\n",
      "\n",
      "Then there's attention. I think it has something to do with focusing on important parts of the input data. For example, in a picture, an image might be more relevant if you're looking at a specific object rather than the entire image. Soattention is about determining how much weight each part gets based on some measure—like importance or relevance.\n",
      "\n",
      "Now, transformers come into play. Transformers… Wait, isn't this related to self- attention? I remember a model called \"Attention is All You Need,\" developed by Vaswani and others. This paper explained that all you need are the encoder and decoder layers, which have a mechanism for each individual token in parallel, processing them with self-attention. Thatself-attention means looking at the sequence to see where related tokens are.\n",
      "\n",
      "Wait, but how does this tie into traditional neural networks? Maybe instead of hidden layers or multiple layers like RNNs (which look back in time), transformers use a self-attention mechanism within each layer that allows parallel processing. Also, I've heard about attention masks being important because they focus the model on relevant parts for the task.\n",
      "\n",
      "Putting this all together: Neural networks process data through layers and nodes, perhaps combining their outputs with non-linear activations like ReLU or others. Attention is how models decide which input elements to emphasize based on some scoring function. Transformers use self-attention in an iterative way, so each token can attend to every other token across the sequence at various steps. This allows transformers to process sequential data efficiently and model long-range dependencies.\n",
      "\n",
      "I'm still a bit confused about the initial claim that LLMs are based solely on attention? I mean, isn't a language model more about understanding context and generating text by looking back in time (like with some form of RNN or hidden layer) than focusing attention on specific parts? So maybe I got it mixed up. Perhaps \"transformers\" don’t solely use attention but use self-attention mechanisms within their architecture.\n",
      "\n",
      "Also, LLMs often involve both attention for the model itself and fine-grained features in the text. Maybe the model's own reasoning uses attention to identify important phrases or words, while looking at the text with a global structure helps it make sense of all those words. That makes sense because language has context, so the model might need to attend globally as well.\n",
      "\n",
      "So, putting it all together: LLMs use neural networks to process both fine-grained (word level) and global (contextual) information. Attention allows models like transformers to focus on important local context, while the overall structure of the text provides the contextual understanding needed for tasks like answering questions or generating coherent responses.\n",
      "\n",
      "I think I'm starting to get a grasp of it now. The key is that neural networks handle the fine details and contexts within words and phrases, while attention helps the model focus on what's most relevant in the larger context, which includes both the text content and the specific intent being addressed.\n",
      "</think>\n",
      "\n",
      "**Understanding the Core Concepts Behind LLMs**\n",
      "\n",
      "**1. Neural Networks:**\n",
      "Neural networks process data through layered nodes or neurons, where each layer processes information differently. They aim to simulate the human brain by combining input from previous layers into a final decision or prediction. The key idea is how these layers interact, allowing for collective processing of data.\n",
      "\n",
      "**2. Attention Mechanism:**\n",
      "The attention mechanism focuses on extracting relevant parts of the input data. It assigns weights based on factors like relevance or importance, such as visual parts of an image being more relevant to a specific object than the entire picture.\n",
      "\n",
      "**3. Transformers (Self-Attention within Layers):**\n",
      "Transformers use self-attention, a mechanism where each token in a sequence attends to all others, allowing parallel processing within encoders and decoders. This enables efficient handling of sequential data, addressing long-range dependencies through iterative attention.\n",
      "\n",
      "**4. LLMs:**\n",
      "LLMs are based on neural networks that process both fine-grained (word level) and global contextual information. Contextual understanding allows tasks like answering questions or generating coherent responses by focusing on word-level and text-based reasoning in conjunction with attention mechanisms.\n",
      "\n",
      "In summary, LLMs leverage both local (fine-grained details) and global (contextual) processing using neural networks and attention to enhance their ability to generate and understand language.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=DEEPSEEK_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a5bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb63c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(model=MODEL, messages=messages_for(website), stream=False)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d2de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91e21d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary of The H.P. Lovecraft Archive**\n",
       "\n",
       "### Overview\n",
       "The H.P. Lovecraft Archive is a comprehensive online repository dedicated to the life, works, and legacy of American author Howard Phillips Lovecraft.\n",
       "\n",
       "### Content\n",
       "\n",
       "* **His Life**: Provides biographical information on Lovecraft's family, correspondents, interests, and more.\n",
       "* **His Writings**: Explores his fiction and letters, including electronic texts and bibliographies.\n",
       "* **His Creations**: Outlines fictional elements such as locations, bestiary, and grimoires inspired by Lovecraft's works.\n",
       "* **His Study**: Offers biographical summaries, literary criticism, bibliographies, and more.\n",
       "\n",
       "### Popular Culture\n",
       "Details movies, games, music, art, and the \"Cthulhu Mythos\" based on Lovecraft's works.\n",
       "\n",
       "### Internet Resources\n",
       "Lists other Lovecraft-related sites, newsgroups, and FTP sites.\n",
       "\n",
       "### News and Announcements\n",
       "\n",
       "* **2025**: New pages created for \"Alcestis: A Play\", \"Two Hearts that Beat as One: An Autobiography\", and more.\n",
       "* **2024**:\n",
       "\t+ November 11: New editions of \"The Shunned House\" and \"Night Black Deeds\".\n",
       "\t+ September 12: Page created for \"The Case of Charles Dexter Ward\".\n",
       "\t+ August 20: Happy Birthday to H.P. Lovecraft!\n",
       "\t+ August 8: Four new publications from Hippocampus Press were added.\n",
       "* **2024**: Table of contents for Lovecraft Annual number 18 was added to the periodicals database.\n",
       "\n",
       "### Site Information\n",
       "The site is maintained by Donovan K. Loucks and is copyrighted since 1998-2025."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.hplovecraft.com/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
